{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the actual code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import base64\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import os  # At the top of your script\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tkinter import ttk\n",
    "import io\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key from environment variable\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set OPENAI_API_KEY in your .env file\")\n",
    "\n",
    "\n",
    "class FileSelectionDialog:\n",
    "    def close_gui(self):\n",
    "        \"\"\"Safely close the GUI from the main thread.\"\"\"\n",
    "        self.root.destroy()\n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"File Selections\")\n",
    "        self.update_queue = queue.Queue()  # Queue to hold update tasks\n",
    "\n",
    "        # Initialize variables\n",
    "        self.pdf_path = None\n",
    "        self.report_path = None\n",
    "        self.total_pages = 0\n",
    "        self.max_pages = 1000000  ##Incase you want to test you can lower this variable\n",
    "        self.class_name = None\n",
    "        self.subject_name = None\n",
    "        self.start_page = 1  # Default start page\n",
    "        self.stop_page = None\n",
    "\n",
    "        self.setup_widgets()\n",
    "        self.poll_queue()  # Start polling the queue for updates\n",
    "\n",
    "    def poll_queue(self):\n",
    "        \"\"\"Check the queue for new messages\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                message = self.update_queue.get_nowait()\n",
    "                if message == (\"close\",):  # Check for the close signal\n",
    "                    self.close_gui()\n",
    "                else:\n",
    "                    current_page, total_pages = message\n",
    "                    self.update_progress(current_page, total_pages)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            # Schedule another call to this method if the root is still alive\n",
    "            if self.root.winfo_exists():\n",
    "                self.root.after(100, self.poll_queue)\n",
    "\n",
    "    def safe_update_progress(self, current_page, total_pages):\n",
    "        \"\"\"Enqueue the progress update.\"\"\"\n",
    "        self.update_queue.put((current_page, total_pages))\n",
    "\n",
    "    def setup_widgets(self):\n",
    "        # Add class selection\n",
    "        tk.Label(self.root, text=\"Enter Class Name:\").pack(padx=20, pady=5)\n",
    "        self.class_entry = tk.Entry(self.root)\n",
    "        self.class_entry.pack(pady=(0, 10))\n",
    "\n",
    "        # Add subject selection\n",
    "        tk.Label(self.root, text=\"Select Subject:\").pack(padx=20, pady=5)\n",
    "        self.subject_combo = ttk.Combobox(\n",
    "            self.root,\n",
    "            values=[\"SST\", \"Mathematics\", \"Science\", \"English\", \"CRE\"],\n",
    "            state=\"readonly\",\n",
    "        )  # readonly prevents typing\n",
    "        self.subject_combo.pack(pady=(0, 20))\n",
    "        self.subject_combo.set(\"SST\")\n",
    "\n",
    "        tk.Label(self.root, text=\"Select the source PDF file:\").pack(padx=20, pady=5)\n",
    "        self.pdf_button = tk.Button(\n",
    "            self.root, text=\"Choose PDF\", command=self.select_pdf_file\n",
    "        )\n",
    "        self.pdf_button.pack(pady=(0, 20))\n",
    "\n",
    "        tk.Label(\n",
    "            self.root,\n",
    "            text=\"Select the path and set a name for saving the Excel report:\",\n",
    "        ).pack(padx=20, pady=5)\n",
    "        self.report_button = tk.Button(\n",
    "            self.root, text=\"Choose Report Path\", command=self.select_output_path\n",
    "        )\n",
    "        self.report_button.pack(pady=(0, 20))\n",
    "\n",
    "        start_page_frame = tk.Frame(self.root)\n",
    "        start_page_frame.pack(pady=10)\n",
    "\n",
    "        tk.Label(start_page_frame, text=\"Start from page (optional):\").pack(\n",
    "            side=tk.LEFT, padx=5\n",
    "        )\n",
    "        self.start_page_entry = tk.Entry(start_page_frame, width=10)\n",
    "        self.start_page_entry.pack(side=tk.LEFT, padx=5)\n",
    "        self.start_page_entry.insert(0, \"1\")  # Default value\n",
    "\n",
    "        stop_page_frame = tk.Frame(self.root)\n",
    "        stop_page_frame.pack(pady=10)\n",
    "\n",
    "        tk.Label(stop_page_frame, text=\"Stop at page (optional):\").pack(\n",
    "            side=tk.LEFT, padx=5\n",
    "        )\n",
    "        self.stop_page_entry = tk.Entry(stop_page_frame, width=10)\n",
    "        self.stop_page_entry.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Add validation for numeric input\n",
    "        def validate_page_number(P):\n",
    "            if P == \"\":\n",
    "                return True\n",
    "            return P.isdigit() and int(P) > 0\n",
    "\n",
    "        vcmd = (self.root.register(validate_page_number), \"%P\")\n",
    "        self.start_page_entry.config(validate=\"key\", validatecommand=vcmd)\n",
    "\n",
    "        # Label to display the selected directory and the default filename\n",
    "        self.report_path_label = tk.Label(self.root, text=\"\")\n",
    "        self.report_path_label.pack(pady=(5, 10))  # Adjust padding as necessary\n",
    "\n",
    "        self.confirm_button = tk.Button(\n",
    "            self.root, text=\"Confirm Selections\", command=self.confirm_selections\n",
    "        )\n",
    "        self.confirm_button.pack(pady=20)\n",
    "\n",
    "        # Progress label\n",
    "        self.progress_label = tk.Label(self.root, text=\"\")\n",
    "        self.progress_label.pack(pady=10)\n",
    "\n",
    "        # New progress label for misconceptions analysis\n",
    "        self.analysis_progress_label = tk.Label(self.root, text=\"\")\n",
    "        self.analysis_progress_label.pack(pady=10)\n",
    "\n",
    "    def select_pdf_file(self):\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select the source PDF File\", filetypes=[(\"PDF Files\", \"*.pdf\")]\n",
    "        )\n",
    "        if file_path:\n",
    "            self.pdf_path = file_path\n",
    "            self.pdf_button.config(text=f\"Selected: {file_path.split('/')[-1]}\")\n",
    "\n",
    "            # Get the total number of pages in the PDF\n",
    "            try:\n",
    "                doc = fitz.open(self.pdf_path)\n",
    "                self.total_pages = len(doc)\n",
    "                doc.close()\n",
    "                self.progress_label.config(\n",
    "                    text=f\"Document has {self.total_pages} pages.\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Failed to read the PDF: {e}\")\n",
    "                self.pdf_path = None\n",
    "                self.total_pages = 0\n",
    "\n",
    "    def select_output_path(self):\n",
    "        directory = filedialog.askdirectory(\n",
    "            title=\"Select the directory to save the report\"\n",
    "        )\n",
    "        if directory:\n",
    "            current_time = datetime.now()\n",
    "            formatted_time = current_time.strftime(\"%d_%m_%Y_%H_%M\")\n",
    "            class_name = self.class_entry.get().strip().replace(\" \", \"_\")\n",
    "            subject_name = self.subject_combo.get().strip().replace(\" \", \"_\")\n",
    "\n",
    "            default_filename = (\n",
    "                f\"exam_report_{class_name}_{subject_name}_{formatted_time}.xlsx\"\n",
    "            )\n",
    "            self.report_path = os.path.join(directory, default_filename)\n",
    "            self.report_directory = directory  # Save the directory if needed elsewhere\n",
    "            self.report_button.config(text=f\"Path Selected: {directory}\")\n",
    "            self.report_path_label.config(\n",
    "                text=f\"Directory: {directory}\\nFile will be saved as: {default_filename}\"\n",
    "            )\n",
    "\n",
    "    def confirm_selections(self):\n",
    "        \"\"\"Handle the confirmation of file selections.\"\"\"\n",
    "        self.class_name = self.class_entry.get().strip()\n",
    "        self.subject_name = self.subject_combo.get().strip()\n",
    "\n",
    "        # Get and validate start page\n",
    "        try:\n",
    "            start_page = int(self.start_page_entry.get())\n",
    "            stop_page_text = self.stop_page_entry.get().strip()\n",
    "            stop_page = int(stop_page_text) if stop_page_text else self.total_pages\n",
    "\n",
    "            if start_page < 1 or (self.total_pages and start_page > self.total_pages):\n",
    "                messagebox.showerror(\n",
    "                    \"Error\", f\"Start page must be between 1 and {self.total_pages}\"\n",
    "                )\n",
    "                return\n",
    "\n",
    "            if stop_page < start_page or (self.total_pages and stop_page > self.total_pages):\n",
    "                messagebox.showerror(\n",
    "                    \"Error\",\n",
    "                    f\"Stop page must between {start_page} and {self.total_pages}\",\n",
    "                )\n",
    "                return\n",
    "            \n",
    "            self.start_page = start_page\n",
    "            self.stop_page = stop_page\n",
    "\n",
    "        except ValueError:\n",
    "            if stop_page_text and not stop_page_text.isdigit():\n",
    "                messagebox.showerror(\"Error\", \"Stop page must be a valid number\")\n",
    "                return\n",
    "            self.start_page = 1  # Default to first page if invalid input\n",
    "            self.stop_page = self.total_pages\n",
    "\n",
    "        if (\n",
    "            not self.pdf_path\n",
    "            or not self.report_path\n",
    "            or not self.class_name\n",
    "            or not self.subject_name\n",
    "        ):\n",
    "            messagebox.showerror(\n",
    "                \"Error\",\n",
    "                \"Please fill in all fields (PDF, Report path, Class, and Subject)\",\n",
    "            )\n",
    "        else:\n",
    "            self.pdf_button.config(state=tk.DISABLED)\n",
    "            self.report_button.config(state=tk.DISABLED)\n",
    "            self.class_entry.config(state=tk.DISABLED)\n",
    "            self.subject_combo.config(state=tk.DISABLED)\n",
    "            self.start_page_entry.config(state=tk.DISABLED)\n",
    "            self.stop_page_entry.config(state=tk.DISABLED)\n",
    "            self.confirm_button.config(state=tk.DISABLED)\n",
    "            print(\"Selections confirmed. Ready for processing.\")\n",
    "            self.root.quit()  # Quit the Tkinter event loop\n",
    "\n",
    "    def reset_selections(self):\n",
    "        self.pdf_path = None\n",
    "        self.report_path = None\n",
    "        self.total_pages = 0\n",
    "        self.pdf_button.config(text=\"Choose PDF\")\n",
    "        self.report_button.config(text=\"Choose Report Path\")\n",
    "        self.progress_label.config(text=\"\")\n",
    "\n",
    "    def update_progress(self, current_page, total_pages):\n",
    "        \"\"\"Update the progress label dynamically.\"\"\"\n",
    "        stop_page = self.stop_page if self.stop_page else total_pages\n",
    "        self.progress_label.config(\n",
    "            text=f\"Processing page {current_page + 1}/{stop_page} of {total_pages} pages...\"\n",
    "        )\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "    def update_analysis_progress(self, current_item, total_items):\n",
    "        \"\"\"Update the analysis progress label directly called by the GUI thread.\"\"\"\n",
    "        self.analysis_progress_label.config(\n",
    "            text=f\"Analysing responses {current_item}/{total_items}...\"\n",
    "        )\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "    def update_topic_progress(self, current_question, total_questions):\n",
    "        \"\"\"Update the topic analysis progress label directly called by the GUI thread.\"\"\"\n",
    "        self.analysis_progress_label.config(\n",
    "            text=f\"Categorizing topics: Question {current_question}/{total_questions}...\"\n",
    "        )\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "\n",
    "def encode_image_to_base64(pixmap):\n",
    "    \"\"\"Encode a PyMuPDF pixmap to a base64 string.\"\"\"\n",
    "    img_bytes = pixmap.tobytes(\"png\")\n",
    "    return base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def robust_process_image(base64_image, last_known_student_name, retries=6, delay=16):\n",
    "    attempt = 0\n",
    "    last_exception = None\n",
    "    while attempt < retries:\n",
    "        response_content = None\n",
    "        try:\n",
    "            response_content = process_image(base64_image, last_known_student_name)\n",
    "            if not (\n",
    "                isinstance(response_content, dict)\n",
    "                and \"studentName\" in response_content\n",
    "                and \"entries\" in response_content\n",
    "            ):\n",
    "                raise KeyError(\"Response does not conform to the expected JSON schema.\")\n",
    "            if response_content:\n",
    "                return response_content, None\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError, Exception) as e:\n",
    "            last_exception = e\n",
    "            print(f\"Request failed with error: {e}. Retrying...\")\n",
    "            time.sleep(delay)\n",
    "            attempt += 1\n",
    "        except (KeyError) as e:\n",
    "            last_exception = e\n",
    "            print(\"Key error:\", e)\n",
    "            print(\"Response was:\", response_content)\n",
    "            print(\"Retrying...\")\n",
    "            time.sleep(delay)\n",
    "            attempt += 1\n",
    "        else:\n",
    "            try:\n",
    "                if (\n",
    "                    \"error\" in response_content\n",
    "                    and response_content[\"error\"][\"message\"]\n",
    "                    == \"The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.\"\n",
    "                ):\n",
    "                    print(\"Model produced invalid content error received. Retrying...\")\n",
    "                    time.sleep(delay)\n",
    "                    attempt += 1\n",
    "                elif (\n",
    "                    \"error\" in response_content\n",
    "                    and response_content[\"error\"][\"message\"]\n",
    "                    == \"You uploaded an unsupported image. Please make sure your image is below 20 MB in size and is of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\"\n",
    "                ):\n",
    "                    print(\"Unsupported image format or size error received. Retrying...\")\n",
    "                    time.sleep(delay)\n",
    "                    attempt += 1\n",
    "            except (TypeError, KeyError):\n",
    "                print(\"Unexpected response format or missing data. Retrying...\")\n",
    "                time.sleep(delay)\n",
    "                attempt += 1\n",
    "    print(f\"robust_process_image: failed after {retries} retries. Last exception: {last_exception}\")\n",
    "    return None, last_exception\n",
    "\n",
    "\n",
    "def save_page_image(base64_image, original_file_name, page_number, report_directory):\n",
    "    \"\"\"\n",
    "    Save the page image to a 'page-pictures' subdirectory within the report directory.\n",
    "\n",
    "    Args:\n",
    "        base64_image: The base64 encoded image data\n",
    "        original_file_name: Name of the original PDF file\n",
    "        page_number: Current page number\n",
    "        report_directory: The directory where the report will be saved\n",
    "    \"\"\"\n",
    "    # Create page-pictures folder within the report directory\n",
    "    output_folder = os.path.join(report_directory, \"page_pictures\")\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Format the filename\n",
    "    image_filename = f\"{original_file_name}_page{page_number}.png\"\n",
    "\n",
    "    try:\n",
    "        # Decode the base64 string to bytes\n",
    "        image_data = base64.b64decode(base64_image)\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        # Save the image\n",
    "        save_path = os.path.join(output_folder, image_filename)\n",
    "        image.save(save_path)\n",
    "        print(f\"Image saved to {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image: {e}\")\n",
    "\n",
    "\n",
    "def process_image(base64_image, last_known_student_name):\n",
    "    \"\"\"Send the base64 image to OpenAI, returning the parsed content with a dynamic prompt.\"\"\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"}\n",
    "    prompt_text = (\n",
    "        f\"In this image, first identify if there is a field at the top of the page explicitly \"\n",
    "        f\"labelled 'Name' followed by a colon or on the right of a label 'Name:' on the same line. \"\n",
    "        f\"If such a label exists and a name immediately follows it on the same line, extract that \"\n",
    "        f\"name and assign it as the value of 'studentName' in the output JSON object. \"\n",
    "        f\"If the Name label is not followed by a name on the same line or if the label does not \"\n",
    "        f\"exist, use '{last_known_student_name}' as the studentName. For the rest of the content, \"\n",
    "        f\"transcribe only the exam questions into an array of entries. Each entry must be a JSON \"\n",
    "        f\"object with exactly the following keys: 'questionNo', 'question', 'answer', and 'grading'. \"\n",
    "        f\"The output must be a valid JSON object with the following structure:\\n\"\n",
    "        f'{{ \"studentName\": \"<Extracted or default name>\", \"entries\": [ {{ \"questionNo\": \"<Question number>\", '\n",
    "        f'\"question\": \"<Question text>\", \"answer\": \"<Answer text>\", \"grading\": \"<Correct/Incorrect/Not Graded or '\n",
    "        f'empty string>\" }}, ... ] }} '\n",
    "        f\"For questions with multiple parts (e.g., 36(a)), if there are multiple answers, produce a separate entry \"\n",
    "        f\"for each answer, repeating the question text for each part. If a question provides an option to answer \"\n",
    "        f\"either one part or the other, transcribe only the part that was answered. If the student hasn't answered, \"\n",
    "        f\"leave the 'answer' field empty. Grade each answer as 'Correct' if there is a red tick mark. If an answer \"\n",
    "        f\"has any marks other than a red tick mark and does not have a red tick mark, treat it as 'Incorrect'. \"\n",
    "        f\"If an answer contains a red tick mark along with other marks, treat it as 'Correct'. If no mark is present \"\n",
    "        f\"at all, grade it as 'Not Graded'. Ensure no extra spaces are added at the beginning or end of any text values, \"\n",
    "        f\"and ignore any non-exam instructions. Your response must be a single, valid JSON object and nothing else. Do not wrap it in markdown code blocks.\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"ft:gpt-4o-2024-08-06:personal:my-answersheet-experiment-28-12-2024:AjKchLD0\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt_text},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"high\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 1500,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload\n",
    "    )\n",
    "    print(\"Prompt text:\")\n",
    "    print(prompt_text)\n",
    "    print(\"\\nRaw API response text:\")\n",
    "    print(response.text)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "    # Get the raw content from the assistant\n",
    "    raw_content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"Raw content from API:\")\n",
    "    print(raw_content)\n",
    "\n",
    "    # Attempt to parse the JSON directly first\n",
    "    try:\n",
    "        parsed_response = json.loads(raw_content)\n",
    "        print(\"\\nParsed JSON object directly:\")\n",
    "        print(parsed_response)\n",
    "        return parsed_response\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Direct JSON parsing failed. Attempting to extract from markdown.\")\n",
    "        # Fallback: Extract JSON from markdown code block if present\n",
    "        match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", raw_content, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(1)\n",
    "            try:\n",
    "                parsed_response = json.loads(json_str)\n",
    "                print(\"\\nParsed JSON object from markdown:\")\n",
    "                print(parsed_response)\n",
    "                return parsed_response\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"\\nJSONDecodeError after extracting from markdown:\")\n",
    "                print(e)\n",
    "                raise e  # Re-raise the specific error\n",
    "        \n",
    "        # Fallback 2: Find the first and last curly brace\n",
    "        start = raw_content.find(\"{\")\n",
    "        end = raw_content.rfind(\"}\") + 1\n",
    "        if start != -1 and end > start:\n",
    "            json_str = raw_content[start:end]\n",
    "            try:\n",
    "                parsed_response = json.loads(json_str)\n",
    "                print(\"\\nParsed JSON object using brace finding:\")\n",
    "                print(parsed_response)\n",
    "                return parsed_response\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"\\nJSONDecodeError after finding braces:\")\n",
    "                print(e)\n",
    "                raise e\n",
    "\n",
    "        # If all parsing attempts fail, raise an error\n",
    "        raise json.JSONDecodeError(\"Failed to find or parse JSON in the response.\", raw_content, 0)\n",
    "\n",
    "\n",
    "def get_question_numbers_from_json(entries):\n",
    "    \"\"\"\n",
    "    entries is a list of dicts, each dict representing one question item, e.g.:\n",
    "        {\n",
    "          \"questionNo\": \"45(a)\",\n",
    "          \"question\": \"Write two steps...\",\n",
    "          \"answer\": \"Evicting people...\",\n",
    "          \"grading\": \"Correct\"\n",
    "        }\n",
    "    We want to find the first and last fully numeric questionNo (e.g. '45').\n",
    "    \"\"\"\n",
    "\n",
    "    first_question_number = \"N/A\"\n",
    "    last_question_number = \"N/A\"\n",
    "\n",
    "    question_numbers = []\n",
    "    for item in entries:\n",
    "        # Get the question number field, e.g. \"45(a)\"\n",
    "        q_number = item.get(\"questionNo\", \"\")\n",
    "        # Remove parentheses parts like (a), (i) etc.\n",
    "        q_number_cleaned = re.sub(r\"\\(.*?\\)\", \"\", q_number).strip()\n",
    "        question_numbers.append(q_number_cleaned)\n",
    "\n",
    "    # Now filter to numeric question numbers, e.g. \"45\"\n",
    "    numeric_question_numbers = [num for num in question_numbers if num.isdigit()]\n",
    "    if numeric_question_numbers:\n",
    "        first_question_number = numeric_question_numbers[0]\n",
    "        last_question_number = numeric_question_numbers[-1]\n",
    "\n",
    "    return first_question_number, last_question_number\n",
    "\n",
    "\n",
    "def process_pdf(\n",
    "    dialog,\n",
    "    doc,\n",
    "    last_question,\n",
    "    current_student_name,\n",
    "    csv_file_path,\n",
    "    jsonl_file_path,\n",
    "    start_page=1,\n",
    "    stop_page=None,\n",
    "):\n",
    "    start_idx = start_page - 1\n",
    "    stop_idx = stop_page if stop_page else len(doc)\n",
    "    original_file_name = os.path.basename(dialog.pdf_path).replace(\".pdf\", \"\")\n",
    "\n",
    "    failed_pages = []  # To keep track of skipped pages and reasons\n",
    "\n",
    "    with open(csv_file_path, mode=\"w\", encoding=\"utf-8\") as csv_file, open(\n",
    "        jsonl_file_path, mode=\"w\", encoding=\"utf-8\"\n",
    "    ) as jsonl_file:\n",
    "\n",
    "        csv_file.write(\n",
    "            \"Student Name,Question No,Question,Answer,Grading,PageNumber,ClassName,SubjectName\\n\"\n",
    "        )\n",
    "\n",
    "        num_pages_to_process = min(stop_idx, dialog.max_pages)\n",
    "        className = str(dialog.class_name).strip()\n",
    "        subjectName = str(dialog.subject_name).strip()\n",
    "\n",
    "        for page_num in range(start_idx, num_pages_to_process):\n",
    "            dialog.safe_update_progress(page_num, dialog.total_pages)\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            base64_image = encode_image_to_base64(pix)\n",
    "\n",
    "            save_page_image(\n",
    "                base64_image, original_file_name, page_num + 1, dialog.report_directory\n",
    "            )\n",
    "\n",
    "            print(f\"Processing page {page_num + 1}/{dialog.total_pages}...\")\n",
    "            response_json, last_exception = robust_process_image(base64_image, current_student_name)\n",
    "            if response_json is None:\n",
    "                print(f\"Failed to process page {page_num + 1} after retries. Skipping.\")\n",
    "                failed_pages.append({\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"reason\": str(last_exception)\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            student_name_extracted = response_json.get(\n",
    "                \"studentName\", current_student_name\n",
    "            )\n",
    "            entries = response_json.get(\"entries\", [])\n",
    "\n",
    "            if student_name_extracted:\n",
    "                current_student_name = student_name_extracted\n",
    "\n",
    "            first_question, last_question = get_question_numbers_from_json(entries)\n",
    "            print(f\"First question number: {first_question}\")\n",
    "            print(f\"Last question number: {last_question}\")\n",
    "\n",
    "            if entries:\n",
    "                for entry in entries:\n",
    "                    question_no = entry.get(\"questionNo\", \"\")\n",
    "                    question = entry.get(\"question\", \"\")\n",
    "                    answer = entry.get(\"answer\", \"\")\n",
    "                    grading = entry.get(\"grading\", \"\")\n",
    "                    page_str = str(page_num + 1)\n",
    "                    question_escaped = question.replace('\"', '\"\"')\n",
    "                    answer_escaped = answer.replace('\"', '\"\"')\n",
    "                    grading_escaped = grading.replace('\"', '\"\"')\n",
    "                    quoted_question = f'\"{question_escaped}\"'\n",
    "                    quoted_answer = f'\"{answer_escaped}\"'\n",
    "                    quoted_grading = f'\"{grading_escaped}\"'\n",
    "                    quoted_class = f'\"{className}\"'\n",
    "                    quoted_subject = f'\"{subjectName}\"'\n",
    "                    csv_row = \",\".join(\n",
    "                        [\n",
    "                            student_name_extracted,\n",
    "                            question_no,\n",
    "                            quoted_question,\n",
    "                            quoted_answer,\n",
    "                            quoted_grading,\n",
    "                            page_str,\n",
    "                            quoted_class,\n",
    "                            quoted_subject,\n",
    "                        ]\n",
    "                    )\n",
    "                    csv_file.write(csv_row + \"\\n\")\n",
    "                    jsonl_obj = {\n",
    "                        \"studentName\": student_name_extracted,\n",
    "                        \"questionNo\": question_no,\n",
    "                        \"question\": question,\n",
    "                        \"answer\": answer,\n",
    "                        \"grading\": grading,\n",
    "                        \"pageNumber\": page_num + 1,\n",
    "                        \"className\": className,\n",
    "                        \"subjectName\": subjectName,\n",
    "                    }\n",
    "                    jsonl_file.write(json.dumps(jsonl_obj) + \"\\n\")\n",
    "            else:\n",
    "                csv_file.write(student_name_extracted + \",,,,\\n\")\n",
    "                jsonl_file.write(\n",
    "                    json.dumps({\"studentName\": student_name_extracted}) + \"\\n\"\n",
    "                )\n",
    "\n",
    "    # === Report skipped/failed pages at the end ===\n",
    "    if failed_pages:\n",
    "        print(\"\\nThe following pages failed after all retries and were skipped:\")\n",
    "        for fail in failed_pages:\n",
    "            print(f\"Page {fail['page']}: {fail['reason']}\")\n",
    "        # Optionally save to disk\n",
    "        fail_path = csv_file_path.replace('.csv', '_failed_pages.json')\n",
    "        with open(fail_path, \"w\") as f:\n",
    "            json.dump(failed_pages, f, indent=2)\n",
    "        print(f\"\\nFailed page log written to: {fail_path}\")\n",
    "\n",
    "def categorize_questions_by_topic(dialog, questions_df, output_path, subject_name=\"SST\"):\n",
    "    \"\"\"\n",
    "    Categorize questions by topic using OpenAI API in a batch.\n",
    "    \n",
    "    Args:\n",
    "        questions_df: DataFrame containing questions\n",
    "        output_path: Path to save the output Excel file\n",
    "        subject_name: Name of the subject (e.g., 'SST')\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False if error occurred\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"DEBUG: questions_df shape:\", questions_df.shape)\n",
    "        print(\"DEBUG: questions_df columns:\", questions_df.columns.tolist())\n",
    "        print(\"DEBUG: questions_df head:\")\n",
    "        print(questions_df.head(10))\n",
    "\n",
    "        # Define subject topics mapping\n",
    "        subject_topics = {\n",
    "            \"SST\": [\n",
    "                \"Physical and Human Geography\",\n",
    "                \"Civics and Governance\",\n",
    "                \"History and Heritage\",\n",
    "                \"Economic Activities and Development\",\n",
    "                \"Social Systems and Practices\",\n",
    "                \"Environmental Conservation and Management\",\n",
    "            ],\n",
    "            \"Mathematics\": [\n",
    "                \"Numbers and Numeration\",\n",
    "                \"Basic Operations (Addition, Subtraction, Multiplication, Division)\",\n",
    "                \"Fractions and Decimals\",\n",
    "                \"Measurement (Length, Mass, Capacity, Time)\",\n",
    "                \"Geometry and Shapes\",\n",
    "                \"Money and Consumer Math\",\n",
    "                \"Statistics and Data Handling\",\n",
    "                \"Algebra and Patterns\"\n",
    "            ],\n",
    "            \"Science\": [\n",
    "                \"Living Things and Life Processes\",\n",
    "                \"Human Body Systems\",\n",
    "                \"Plants and Animals\",\n",
    "                \"Materials and Their Properties\",\n",
    "                \"Energy and Forces\",\n",
    "                \"Earth and Space\",\n",
    "                \"Environmental Science\",\n",
    "                \"Health and Safety\"\n",
    "            ],\n",
    "            \"English\": [\n",
    "                \"Reading Comprehension\",\n",
    "                \"Grammar and Language Structure\",\n",
    "                \"Vocabulary Development\",\n",
    "                \"Writing Skills\",\n",
    "                \"Speaking and Listening\",\n",
    "                \"Literature Appreciation\",\n",
    "                \"Spelling and Punctuation\",\n",
    "                \"Creative Writing\"\n",
    "            ],\n",
    "            \"CRE\": [\n",
    "                \"Biblical Stories and Characters\",\n",
    "                \"Christian Values and Morals\",\n",
    "                \"Prayer and Worship\",\n",
    "                \"Church History\",\n",
    "                \"Religious Ceremonies and Celebrations\",\n",
    "                \"Christian Living\",\n",
    "                \"Biblical Geography\",\n",
    "                \"Faith and Beliefs\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        topics = subject_topics.get(subject_name, [])\n",
    "        if not topics:\n",
    "            print(\"Topic classification not available for this subject\")\n",
    "            questions_df[\"Topic\"] = \"Topic classification not available for this subject\"\n",
    "            questions_df[\"Confidence\"] = 0\n",
    "            questions_df[\"Explanation\"] = \"Topic classification not available for this subject\"\n",
    "            \n",
    "            # Save and return early\n",
    "            with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "                questions_df.to_excel(writer, sheet_name=\"Question Categories\", index=False)\n",
    "                pd.DataFrame().to_excel(writer, sheet_name=\"Topic Statistics\")\n",
    "            return True\n",
    "\n",
    "        # Initialize empty lists to store all results\n",
    "        all_topics = []\n",
    "        all_confidences = []\n",
    "        all_explanations = []\n",
    "        \n",
    "        chunk_size = 30\n",
    "        total_questions = len(questions_df)\n",
    "        total_batches = math.ceil(total_questions / chunk_size)\n",
    "\n",
    "        for batch_num, i in enumerate(range(0, total_questions, chunk_size), 1):\n",
    "            chunk = questions_df.iloc[i:i+chunk_size]\n",
    "            end_idx = min(i + chunk_size, total_questions)\n",
    "            \n",
    "             # Update progress in dialog\n",
    "            progress_msg = f\"Categorizing batch {batch_num} of {total_batches}(Questions {i+1}-{end_idx} of {total_questions})\"\n",
    "            dialog.analysis_progress_label.config(text=progress_msg)\n",
    "            dialog.root.update_idletasks()\n",
    "\n",
    "            prompt = (\n",
    "                f\"Given the following questions from a {subject_name} exam, classify each into one of these topics:\\n\"\n",
    "                f\"{', '.join(topics)}\\n\\n\"\n",
    "                \"Provide your response as a JSON array, where each object corresponds to a question and has these keys:\\n\"\n",
    "                \"- question_no: The question number\\n\"\n",
    "                \"- topic: The most relevant topic from the list above\\n\"\n",
    "                \"- confidence: A number between 0 and 1 indicating confidence in classification\\n\"\n",
    "                \"- explanation: A brief explanation of why this topic was chosen\\n\\n\"\n",
    "                \"Questions:\\n\"\n",
    "                \n",
    "            )\n",
    "            \n",
    "            for idx, row in chunk.iterrows():\n",
    "                prompt += f\"- Question No: {row['Question No']}, Question: {row['Question']}\\n\"\n",
    "            prompt += \"\\nOutput only the JSON array.\\nLeave the Question No as given (e.g., '41(a)', '41(b)(ii)'), and do not convert them to plain integers.\"\n",
    "\n",
    "            print(\"Prompt text:\")\n",
    "            print(prompt)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                headers = {\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    \"max_tokens\": 2500,\n",
    "                }\n",
    "                \n",
    "                response = requests.post(\n",
    "                    \"https://api.openai.com/v1/chat/completions\",\n",
    "                    headers=headers,\n",
    "                    json=payload,\n",
    "                )\n",
    "                print(\"\\nRaw API response text:\")\n",
    "                print(response.text)\n",
    "                \n",
    "                response.raise_for_status()\n",
    "                content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "                print(\"Raw content from API:\")\n",
    "                print(content)\n",
    "                \n",
    "                # Extract and parse JSON\n",
    "                start = content.find(\"[\")\n",
    "                end = content.rfind(\"]\") + 1\n",
    "                if start == -1 or end <= start:\n",
    "                    raise json.JSONDecodeError(\"No JSON array found in response\", content, 0)\n",
    "                \n",
    "                json_str = content[start:end].strip()\n",
    "                results = json.loads(json_str)\n",
    "                \n",
    "                # Process results for this chunk\n",
    "                for idx, row in chunk.iterrows():\n",
    "                    result = next(\n",
    "                        (item for item in results if str(item.get(\"question_no\")) == row[\"Question No\"]),\n",
    "                        None\n",
    "                    )\n",
    "                    if result:\n",
    "                        all_topics.append(result.get(\"topic\", \"\"))\n",
    "                        all_confidences.append(result.get(\"confidence\", 0))\n",
    "                        all_explanations.append(result.get(\"explanation\", \"\"))\n",
    "                    else:\n",
    "                        all_topics.append(\"Classification Failed\")\n",
    "                        all_confidences.append(0)\n",
    "                        all_explanations.append(\"No matching question number found\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk {i//chunk_size + 1}: {str(e)}\")\n",
    "                # Add failed classifications for this chunk\n",
    "                chunk_size = len(chunk)\n",
    "                all_topics.extend([\"Classification Failed\"] * chunk_size)\n",
    "                all_confidences.extend([0] * chunk_size)\n",
    "                all_explanations.extend([\"API error occurred\"] * chunk_size)\n",
    "\n",
    "        # Final progress update\n",
    "        dialog.analysis_progress_label.config(text=\"Topic categorization completed!\")\n",
    "        dialog.root.update_idletasks()\n",
    "        \n",
    "        # Assign results to DataFrame\n",
    "        questions_df[\"Topic\"] = all_topics\n",
    "        questions_df[\"Confidence\"] = all_confidences\n",
    "        questions_df[\"Explanation\"] = all_explanations\n",
    "\n",
    "        # Calculate topic statistics\n",
    "        topic_stats = (\n",
    "            questions_df.groupby(\"Topic\")\n",
    "            .agg({\"Question No\": \"count\"})\n",
    "            .rename(columns={\"Question No\": \"Question Count\"})\n",
    "        )\n",
    "        topic_stats[\"Percentage\"] = (topic_stats[\"Question Count\"] / len(questions_df) * 100).round(2)\n",
    "\n",
    "        # Save to Excel\n",
    "        with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "            questions_df.to_excel(writer, sheet_name=\"Question Categories\", index=False)\n",
    "            topic_stats.to_excel(writer, sheet_name=\"Topic Statistics\")\n",
    "\n",
    "        print(f\"Topic classification completed and saved to {output_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error in topic classification: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def start_processing(\n",
    "    dialog,\n",
    "    doc,\n",
    "    last_question,\n",
    "    current_student_name,\n",
    "    csv_file_path,\n",
    "    xlsx_file_path,\n",
    "    file_directory,\n",
    "    start_page=1,\n",
    "):\n",
    "    # This function will be run in a new thread\n",
    "    try:\n",
    "        jsonl_file_path = csv_file_path.replace(\".csv\", \".jsonl\")\n",
    "        process_pdf(\n",
    "            dialog,\n",
    "            doc,\n",
    "            last_question,\n",
    "            current_student_name,\n",
    "            csv_file_path,\n",
    "            jsonl_file_path,\n",
    "            start_page,\n",
    "            dialog.stop_page,\n",
    "        )\n",
    "\n",
    "        # Add topic categorization\n",
    "        print(\"Starting topic categorization...\")\n",
    "        # Read the processed data\n",
    "        data = pd.read_csv(csv_file_path)\n",
    "        print(\"DEBUG: Raw data head:\")\n",
    "        print(data.head(10))\n",
    "\n",
    "        # Defensive: Check for column names and fix if needed\n",
    "        # expected = [\n",
    "        #     \"Student Name\", \"Question No\", \"Question\",\n",
    "        #     \"Answer\", \"Grading\", \"PageNumber\", \"ClassName\", \"SubjectName\"\n",
    "        # ]\n",
    "        # if list(data.columns)[: len(expected)] != expected:\n",
    "        #     data.columns = expected[: data.shape[1]]\n",
    "        expected_cols = {'Question No', 'Question'}\n",
    "\n",
    "        if not expected_cols.issubset(data.columns):\n",
    "            print(f\"Input file must contain columns: {expected_cols}\")\n",
    "            return False\n",
    "\n",
    "        # Remove rows with missing Question No or Question\n",
    "        clean_questions = (\n",
    "            data.dropna(subset=[\"Question No\", \"Question\"])\n",
    "            .assign(**{\n",
    "                \"Question No\": lambda df: df[\"Question No\"]\n",
    "                .apply(lambda x: str(int(x)) if pd.notnull(x) and str(x).replace('.0','').isdigit() else str(x))\n",
    "            })\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Drop duplicates just in case\n",
    "        unique_questions = clean_questions[[\"Question No\", \"Question\"]].drop_duplicates()\n",
    "        print(\"DEBUG: unique_questions head:\")\n",
    "        print(unique_questions.head(10))\n",
    "\n",
    "\n",
    "        # Generate topic classification output path\n",
    "        topic_output_path = os.path.join(\n",
    "            file_directory,\n",
    "            f\"topic_analysis_{dialog.subject_name}_{datetime.now().strftime('%d_%m_%Y_%H_%M')}.xlsx\",\n",
    "        )\n",
    "\n",
    "        # Run topic categorization\n",
    "        if not categorize_questions_by_topic(dialog,unique_questions, topic_output_path, str(dialog.subject_name).strip()):\n",
    "            print(\"Topic categorization failed, continuing with remaining processing...\")\n",
    "            \n",
    "\n",
    "        print(f\"another possibility for potential file to be ingested iss {csv_file_path}\")\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        formatted_time = current_time.strftime(\n",
    "            \"%d_%m_%Y_%H_%M\"\n",
    "        )  # Format as day_month_year_hour_minute\n",
    "\n",
    "        # Construct filenames with the current date and time\n",
    "        output_filename = f\"transcription_output_{formatted_time}.csv\"\n",
    "        debug_filename = f\"transcription_deletions_{formatted_time}.xlsx\"\n",
    "\n",
    "        output_path = os.path.join(file_directory, output_filename)\n",
    "        print(f\"The output is supposed to go {output_path}\")\n",
    "\n",
    "        debug_output_path = os.path.join(file_directory, debug_filename)\n",
    "        print(f\"The current student name is {debug_output_path}\")\n",
    "\n",
    "        process_transcribed_data(csv_file_path, output_path, debug_output_path)\n",
    "        analyze_misconceptions(dialog, csv_file_path, output_path, xlsx_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processing files: {str(e)}\")\n",
    "    finally:\n",
    "        dialog.update_queue.put((\"close\",))\n",
    "\n",
    "\n",
    "def process_transcribed_data(file_path, output_path, debug_output_path):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path, delimiter=\",\", header=None)\n",
    "    print(f\"Printing data to see format\\n\")\n",
    "\n",
    "    data.columns = [\n",
    "        \"Name\",\n",
    "        \"Question\",\n",
    "        \"Text\",\n",
    "        \"Answer\",\n",
    "        \"Status\",\n",
    "        \"ScanPageNo\",\n",
    "        \"ClassName\",\n",
    "        \"SubjectName\",\n",
    "    ]\n",
    "\n",
    "    # # Add class and subject columns\n",
    "    data[\"ClassName\"] = data[\"ClassName\"].str.replace(r\"[\\(\\)\\[\\]\\']\", \"\", regex=True)\n",
    "    data[\"SubjectName\"] = data[\"SubjectName\"].str.replace(\n",
    "        r\"[\\(\\)\\[\\]\\']\", \"\", regex=True\n",
    "    )\n",
    "\n",
    "    # Filter out rows with only one column\n",
    "    data.dropna(subset=[\"Question\"], inplace=True)\n",
    "\n",
    "    # Delete rows where 'Question No' appears in the 'Question' column\n",
    "    data = data[~data[\"Question\"].str.contains(\"Question No\", na=False)]\n",
    "\n",
    "    # Convert ScanPageNo to integer\n",
    "    data[\"ScanPageNo\"] = data[\"ScanPageNo\"].astype(int)\n",
    "\n",
    "    # Function to correct and format the question number\n",
    "    def correct_question_number(question_number):\n",
    "        corrected = re.sub(r\"(\\d+)\\.([a-z]+)\\.([ivx]+)\", r\"\\1(\\2)(\\3)\", question_number)\n",
    "        corrected = re.sub(r\"(\\d+)\\.([a-z]+)\", r\"\\1(\\2)\", corrected)\n",
    "        corrected = re.sub(r\"(\\d+)\\.\\(([a-z])\\)\\.([ivx]+)\", r\"\\1(\\2)(\\3)\", corrected)\n",
    "        corrected = re.sub(r\"\\.\\(\", \"(\", corrected)\n",
    "        corrected = corrected.replace(\" \", \"\")\n",
    "        return corrected.strip()\n",
    "\n",
    "    # Apply the correction function to the 'Question' column\n",
    "    data[\"Question\"] = data[\"Question\"].apply(correct_question_number)\n",
    "\n",
    "    # Standardize question number formats\n",
    "    def standardize_question_number(question_number):\n",
    "        question_number = re.sub(\n",
    "            r\"(\\d+)([a-z])\\((i{1,3}|iv|v{1,2})\\)\", r\"\\1(\\2)(\\3)\", question_number\n",
    "        )\n",
    "        question_number = re.sub(r\"(\\d+)([a-z])\", r\"\\1(\\2)\", question_number)\n",
    "        return question_number\n",
    "\n",
    "    data[\"Question\"] = data[\"Question\"].apply(standardize_question_number)\n",
    "\n",
    "    # Remove rows which are essentially headers repeated or instructional content\n",
    "    data = data[~data[\"Question\"].str.contains(\"Question No\", na=False)]\n",
    "    data = data.dropna(subset=[\"Question\"])\n",
    "\n",
    "    # Save the cleaned data\n",
    "    data.to_csv(output_path, sep=\"|\", index=False)\n",
    "    print(f\"Data cleaned and saved to {output_path}\")\n",
    "\n",
    "    data.to_excel(output_path.replace(\".csv\", \".xlsx\"), index=False)\n",
    "    print(f\"Data cleaned and saved to {output_path.replace('.csv', '.xlsx')}\")\n",
    "\n",
    "    # Example of handling matched rows for debugging purposes\n",
    "    matched_df = data[data.duplicated(subset=[\"Name\", \"Question\"], keep=False)]\n",
    "    debug_output_path = debug_output_path\n",
    "    matched_df.to_excel(debug_output_path, index=False)\n",
    "    print(f\"Debug file with matched rows saved to {debug_output_path}\")\n",
    "\n",
    "\n",
    "def analyze_misconceptions(dialog, file_path, output_path, xlsx_file_path):\n",
    "    data = pd.read_csv(\n",
    "        file_path,\n",
    "        delimiter=\",\",\n",
    "        names=[\n",
    "            \"Student Name\",\n",
    "            \"Question No\",\n",
    "            \"Question\",\n",
    "            \"Answer\",\n",
    "            \"Grading\",\n",
    "            \"ScanPageNo\",\n",
    "            \"ClassName\",\n",
    "            \"SubjectName\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    def get_common_misconception(question, wrong_answers, correct_answers_sample):\n",
    "        # Ensure all answers are strings and handle NaNs\n",
    "        wrong_answers = [\n",
    "            str(answer) if pd.notna(answer) else \"\" for answer in wrong_answers\n",
    "        ]\n",
    "        wrong_answers_text = \"\\n\".join(wrong_answers)\n",
    "        correct_answers_sample = [\n",
    "            str(answer) if pd.notna(answer) else \"\" for answer in correct_answers_sample\n",
    "        ]\n",
    "        # Remove duplicates by converting the list to a set and back to a list\n",
    "        correct_answers_sample = list(set(correct_answers_sample))\n",
    "        # Join the list into a single string with each element on a new line\n",
    "        correct_answers_text = \"\\n\".join(correct_answers_sample)\n",
    "\n",
    "        prompt = (\n",
    "            f\"The following question had the given wrong answers. \"\n",
    "            f\"Identify the common misconception from these answers and provide a paraphrased explanation. Not all the wrong answers are part of the common misconception; the common misconception is a theme repeated among the wrong answers, so it appears as a subset of the given answers.\\n\\n\"\n",
    "            f\"**Question:** {question}\\n\\n\"\n",
    "            f\"**Wrong Answers:**\\n{wrong_answers_text}\\n\\n\"\n",
    "            f\"Now, please analyze the wrong answers and output your result as a single JSON object with the following keys:\\n\"\n",
    "            f'- \"misconception\": a brief description of the common misconception.\\n'\n",
    "            f'- \"count\": the number of times this misconception appears in the list of wrong answers.\\n\\n'\n",
    "            f\"**Example Output:**\\n\"\n",
    "            f'{{\"misconception\": \"The first president of Uganda is Museveni\", \"count\": 5}}\\n\\n'\n",
    "            f\"Do not include any additional text or formatting; only output the JSON object as shown.\\n\\n\"\n",
    "            f\"Below is a sample of correct answers. It should help guide you to evaluate what the misconceptions above are. Please note that an AI transcriber picked the data above (misconcpetions) and so it could have incorrectly added some to the list.\\n\"\n",
    "            f\"{correct_answers_text}\"\n",
    "        )\n",
    "\n",
    "        # Print the prompt for debugging purposes\n",
    "        print(\"\\n Correct Answers set: as it is in the get common misconceptions file\")\n",
    "        print(correct_answers_sample)\n",
    "        print(f\"Processing {current_sub_question}/{total_sub_questions}\")\n",
    "        print(\"Prompt:\")\n",
    "        print(prompt)\n",
    "        print(\"\\n Correct Answers:\")\n",
    "        print(correct_answers_text)\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 800,\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload\n",
    "        )\n",
    "        response.raise_for_status()  # Raise error if request failed\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Print the response for debugging\n",
    "        print(response_json)\n",
    "\n",
    "        result = json.loads(response_json[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "        misconception = result.get(\"misconception\", \"\")\n",
    "        count = int(result.get(\"count\", 0))\n",
    "        return misconception, count\n",
    "\n",
    "    # Function to extract the main question number\n",
    "\n",
    "    def get_main_question_no(q_no):\n",
    "        q_no = str(q_no)\n",
    "        if \"(\" in q_no:\n",
    "            return q_no.split(\"(\")[0]\n",
    "        return q_no\n",
    "\n",
    "    # Function to extract the sub-question number (up to the second level)\n",
    "    def get_sub_question_no(q_no):\n",
    "        q_no = str(q_no)\n",
    "        if \"(\" in q_no:\n",
    "            parts = q_no.split(\"(\")\n",
    "            return parts[0] + \"(\" + parts[1].split(\")\")[0] + \")\"\n",
    "        return q_no\n",
    "\n",
    "    # Read the data from the text file\n",
    "    #     data = pd.read_csv(file_path, delimiter='|', names=['Student Name', 'Question No', 'Question', 'Answer', 'Grading','ScanPageNo'])\n",
    "    # Add new columns for main and sub-question numbers\n",
    "    data[\"Main Question No\"] = data[\"Question No\"].apply(get_main_question_no)\n",
    "    data[\"Sub Question No\"] = data[\"Question No\"].apply(get_sub_question_no)\n",
    "\n",
    "    # Group by 'Sub Question No'\n",
    "    grouped = data.groupby([\"Sub Question No\"])\n",
    "\n",
    "    # Initialize lists to store the results\n",
    "    results = []\n",
    "\n",
    "    # Get the total number of sub-question numbers\n",
    "    total_sub_questions = len(grouped)\n",
    "    current_sub_question = 0\n",
    "\n",
    "    # Process each group\n",
    "    for name, group in grouped:\n",
    "        current_sub_question += 1\n",
    "        dialog.update_analysis_progress(\n",
    "            current_sub_question, total_sub_questions\n",
    "        )  # Update new progress label\n",
    "        print(f\"Processing {current_sub_question}/{total_sub_questions}\")\n",
    "\n",
    "        sub_question_no = name\n",
    "        main_question_no = group[\"Main Question No\"].iloc[0]\n",
    "        question_text = group[\"Question\"].iloc[0]  # Take the first question text\n",
    "        attempts = len(group)\n",
    "        distinct_students = group[\"Student Name\"].nunique()\n",
    "        correct_answers = (group[\"Grading\"] == \"Correct\").sum()\n",
    "        correct_percentage = (correct_answers / attempts) * 100 if attempts > 0 else 0\n",
    "\n",
    "        # Get the most common misconception from wrong answers using GPT-3.5-turbo\n",
    "        wrong_answers = group[\n",
    "            (group[\"Grading\"] != \"Correct\")\n",
    "            & (pd.notna(group[\"Answer\"]))\n",
    "            & (group[\"Answer\"].str.strip() != \"\")\n",
    "        ][\"Answer\"].tolist()\n",
    "\n",
    "        try:\n",
    "            correct_answers_sample = (\n",
    "                group[\n",
    "                    (group[\"Grading\"].str.contains(\"correct\", case=False, na=False))\n",
    "                    & (pd.notna(group[\"Answer\"]))\n",
    "                    & (group[\"Answer\"].str.strip() != \"\")\n",
    "                ][\"Answer\"]\n",
    "                .sample(n=min(10, correct_answers), random_state=1)\n",
    "                .tolist()\n",
    "            )\n",
    "            print(\"correct_answers_sample just after the set is created\")\n",
    "            print(correct_answers_sample)\n",
    "        except ValueError:\n",
    "            correct_answers_sample = [\"No correct answer transcribed\"]\n",
    "\n",
    "        if wrong_answers:\n",
    "            common_misconception, misconception_frequency = get_common_misconception(\n",
    "                question_text, wrong_answers, correct_answers_sample\n",
    "            )\n",
    "        else:\n",
    "            common_misconception = None\n",
    "            misconception_frequency = 0\n",
    "\n",
    "        results.append(\n",
    "            [\n",
    "                main_question_no,\n",
    "                question_text,\n",
    "                sub_question_no,\n",
    "                attempts,\n",
    "                distinct_students,\n",
    "                correct_answers,\n",
    "                f\"{correct_percentage:.1f}\",\n",
    "                common_misconception,\n",
    "                misconception_frequency,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\n",
    "            \"Main Question No\",\n",
    "            \"Question\",\n",
    "            \"Sub Question No\",\n",
    "            \"Attempts\",\n",
    "            \"Distinct Students\",\n",
    "            \"Correct Answers\",\n",
    "            \"Correct %\",\n",
    "            \"Most Common Misconception\",\n",
    "            \"Misconception Frequency\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Write the results to an Excel file\n",
    "    # Final_report_path = 'C:/Users/maram/Downloads/Python projects/Optical Character recognition/Exam_Report.xlsx'\n",
    "    with pd.ExcelWriter(xlsx_file_path) as writer:\n",
    "        results_df.to_excel(writer, index=False, sheet_name=\"Questions_list\")\n",
    "\n",
    "    print(f\"Report generated successfully: {xlsx_file_path}\")\n",
    "\n",
    "\n",
    "def get_file_selections_and_process():\n",
    "    \"\"\"Run the file selection dialog and process the PDF.\"\"\"\n",
    "    root = tk.Tk()\n",
    "    dialog = FileSelectionDialog(root)\n",
    "    root.mainloop()  # Start the Tkinter event loop\n",
    "\n",
    "    if dialog.pdf_path and dialog.report_path:\n",
    "        csv_file_path = dialog.report_path.replace(\".xlsx\", \".csv\")\n",
    "        xlsx_file_path = dialog.report_path\n",
    "        file_directory = dialog.report_directory\n",
    "        print(f\"Selected PDF Path: {dialog.pdf_path}\")\n",
    "        print(f\"Selected Report Path: {dialog.report_path}\")\n",
    "        print(f\"Class: {dialog.class_name}\")\n",
    "        print(f\"Subject: {dialog.subject_name}\")\n",
    "        print(f\"Starting from page: {dialog.start_page}\")\n",
    "\n",
    "        doc = fitz.open(dialog.pdf_path)\n",
    "        current_student_name = \"\"  # Initialize outside the loop to retain across pages\n",
    "        Prev_last_question_no = (\n",
    "            \"N/A\"  # Initialize outside the loop to retain across page\n",
    "        )\n",
    "        last_question = \"N/A\"  # Initialize outside the loop to retain across page\n",
    "\n",
    "        # Process the PDF\n",
    "        threading.Thread(\n",
    "            target=start_processing,\n",
    "            args=(\n",
    "                dialog,\n",
    "                doc,\n",
    "                last_question,\n",
    "                current_student_name,\n",
    "                csv_file_path,\n",
    "                xlsx_file_path,\n",
    "                file_directory,\n",
    "                dialog.start_page,\n",
    "            ),\n",
    "        ).start()\n",
    "\n",
    "    else:\n",
    "        print(\"No valid selections. Process cancelled.\")\n",
    "    root.mainloop()  # This should be at the end\n",
    "\n",
    "\n",
    "# Run the application\n",
    "get_file_selections_and_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_process_image_old(base64_image, last_known_student_name, retries=6, delay=16):\n",
    "    \"\"\"Attempt to process the image with retries upon failure, including handling specific API errors.\"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        response_content = None  # Initialize here to ensure it's defined even on error\n",
    "        try:\n",
    "            response_content = process_image(base64_image, last_known_student_name)\n",
    "            # Ensure the response is in the new JSON schema format:\n",
    "            print(\"Response keys:\", list(response_content.keys()))\n",
    "            if not (\n",
    "                isinstance(response_content, dict)\n",
    "                and \"studentName\" in response_content\n",
    "                and \"entries\" in response_content\n",
    "            ):\n",
    "                raise KeyError(\"Response does not conform to the expected JSON schema.\")\n",
    "            # If we have a valid response, return it.\n",
    "            if response_content:\n",
    "                return response_content\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "            print(f\"Request failed with error: {e}. Retrying...\")\n",
    "            time.sleep(delay)\n",
    "            attempt += 1\n",
    "\n",
    "        except (\n",
    "            KeyError\n",
    "        ) as e:  # Catch errors in case the response JSON does not contain expected keys\n",
    "            print(\"Printing prompt response below:\")\n",
    "            print(response_content)  # Now this variable is defined (even if None)\n",
    "            print(\"Printed prompt response above:\")\n",
    "            print(\n",
    "                f\"Key error: {e} - likely missing or misformatted data in response.jiba jaba Retrying...\"\n",
    "            )\n",
    "            time.sleep(delay)\n",
    "            attempt += 1\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                # Check for specific error messages indicating unsupported content\n",
    "                if (\n",
    "                    \"error\" in response_content\n",
    "                    and response_content[\"error\"][\"message\"]\n",
    "                    == \"The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.\"\n",
    "                ):\n",
    "                    print(\"Model produced invalid content error received. Retrying...\")\n",
    "                    time.sleep(delay)\n",
    "                    attempt += 1\n",
    "                elif (\n",
    "                    \"error\" in response_content\n",
    "                    and response_content[\"error\"][\"message\"]\n",
    "                    == \"You uploaded an unsupported image. Please make sure your image is below 20 MB in size and is of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\"\n",
    "                ):\n",
    "                    print(\n",
    "                        \"Unsupported image format or size error received. Retrying...\"\n",
    "                    )\n",
    "                    time.sleep(delay)\n",
    "                    attempt += 1\n",
    "            except (TypeError, KeyError):\n",
    "                # Handles scenarios where the response is not in the expected format\n",
    "                print(\"Unexpected response format or missing data. Retrying...\")\n",
    "                time.sleep(delay)\n",
    "                attempt += 1\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_old(\n",
    "    dialog,\n",
    "    doc,\n",
    "    last_question,\n",
    "    current_student_name,\n",
    "    csv_file_path,\n",
    "    jsonl_file_path,\n",
    "    start_page=1,\n",
    "    stop_page=None,\n",
    "):\n",
    "    start_idx = start_page - 1\n",
    "    stop_idx = stop_page if stop_page else len(doc)\n",
    "    original_file_name = os.path.basename(dialog.pdf_path).replace(\".pdf\", \"\")\n",
    "\n",
    "    with open(csv_file_path, mode=\"w\", encoding=\"utf-8\") as csv_file, open(\n",
    "        jsonl_file_path, mode=\"w\", encoding=\"utf-8\"\n",
    "    ) as jsonl_file:\n",
    "\n",
    "        # Write the CSV header row\n",
    "        csv_file.write(\n",
    "            \"Student Name,Question No,Question,Answer,Grading,PageNumber,ClassName,SubjectName\\n\"\n",
    "        )\n",
    "\n",
    "        num_pages_to_process = min(stop_idx, dialog.max_pages)\n",
    "        className = str(dialog.class_name).strip()\n",
    "        subjectName = str(dialog.subject_name).strip()\n",
    "\n",
    "        for page_num in range(start_idx, num_pages_to_process):\n",
    "            dialog.safe_update_progress(page_num, dialog.total_pages)\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            base64_image = encode_image_to_base64(pix)\n",
    "\n",
    "            # Optionally save the image\n",
    "            save_page_image(\n",
    "                base64_image, original_file_name, page_num + 1, dialog.report_directory\n",
    "            )\n",
    "\n",
    "            print(f\"Processing page {page_num + 1}/{dialog.total_pages}...\")\n",
    "            response_json = robust_process_image(base64_image, current_student_name)\n",
    "            if response_json is None:\n",
    "                print(f\"Failed to process page {page_num + 1}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Extract the student name and entries from the JSON response\n",
    "            student_name_extracted = response_json.get(\n",
    "                \"studentName\", current_student_name\n",
    "            )\n",
    "            entries = response_json.get(\"entries\", [])\n",
    "\n",
    "            # Update the current student name for subsequent pages if found\n",
    "            if student_name_extracted:\n",
    "                current_student_name = student_name_extracted\n",
    "\n",
    "            # Optionally, print first and last question numbers\n",
    "            first_question, last_question = get_question_numbers_from_json(entries)\n",
    "            print(f\"First question number: {first_question}\")\n",
    "            print(f\"Last question number: {last_question}\")\n",
    "\n",
    "            # Process each entry\n",
    "            if entries:\n",
    "                for entry in entries:\n",
    "                    question_no = entry.get(\"questionNo\", \"\")\n",
    "                    question = entry.get(\"question\", \"\")\n",
    "                    answer = entry.get(\"answer\", \"\")\n",
    "                    grading = entry.get(\"grading\", \"\")\n",
    "                    page_str = str(page_num + 1)\n",
    "\n",
    "                    # Escape quotes for CSV\n",
    "                    question_escaped = question.replace('\"', '\"\"')\n",
    "                    answer_escaped = answer.replace('\"', '\"\"')\n",
    "                    grading_escaped = grading.replace('\"', '\"\"')\n",
    "\n",
    "                    # Wrap each field that can contain commas or quotes in double quotes\n",
    "                    quoted_question = f'\"{question_escaped}\"'\n",
    "                    quoted_answer = f'\"{answer_escaped}\"'\n",
    "                    quoted_grading = f'\"{grading_escaped}\"'\n",
    "                    quoted_class = f'\"{className}\"'\n",
    "                    quoted_subject = f'\"{subjectName}\"'\n",
    "\n",
    "                    # 1) Create the CSV row\n",
    "                    csv_row = \",\".join(\n",
    "                        [\n",
    "                            student_name_extracted,\n",
    "                            question_no,\n",
    "                            quoted_question,\n",
    "                            quoted_answer,\n",
    "                            quoted_grading,\n",
    "                            page_str,\n",
    "                            quoted_class,\n",
    "                            quoted_subject,\n",
    "                        ]\n",
    "                    )\n",
    "                    csv_file.write(csv_row + \"\\n\")\n",
    "\n",
    "                    # 2) Write JSON line\n",
    "                    jsonl_obj = {\n",
    "                        \"studentName\": student_name_extracted,\n",
    "                        \"questionNo\": question_no,\n",
    "                        \"question\": question,\n",
    "                        \"answer\": answer,\n",
    "                        \"grading\": grading,\n",
    "                        \"pageNumber\": page_num + 1,\n",
    "                        \"className\": className,\n",
    "                        \"subjectName\": subjectName,\n",
    "                    }\n",
    "                    jsonl_file.write(json.dumps(jsonl_obj) + \"\\n\")\n",
    "            else:\n",
    "                # No entries, write at least a student name placeholder\n",
    "                csv_file.write(student_name_extracted + \",,,,\\n\")\n",
    "                jsonl_file.write(\n",
    "                    json.dumps({\"studentName\": student_name_extracted}) + \"\\n\"\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoresight_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
